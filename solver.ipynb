{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "from PIL import ImageGrab\n",
    "from math import floor, ceil\n",
    "from enum import Enum\n",
    "import time\n",
    "import win32api, win32con, time\n",
    "import rich.status\n",
    "from rich.progress import (\n",
    "    TimeElapsedColumn,\n",
    "    TextColumn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_bytes = ['1C', '7A', '55', 'BD', 'E9', 'FF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_o = cv2.imread('./test_input2.png')\n",
    "image = cv2.cvtColor(image_o, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_template_o = cv2.imread('./templates/code_matrix_header.png')\n",
    "header_template = cv2.cvtColor(header_template_o, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_templates = {}\n",
    "for byte in valid_bytes:\n",
    "    byte_template =  cv2.imread('./templates/' + byte.lower() + '.png')\n",
    "    byte_templates[byte] = cv2.cvtColor(byte_template, cv2.COLOR_BGR2GRAY)\n",
    "target_byte_templates = {}\n",
    "for byte in valid_bytes:\n",
    "    byte_template =  cv2.imread('./templates/t_' + byte.lower() + '.png')\n",
    "    target_byte_templates[byte] = cv2.cvtColor(byte_template, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(image_input, template, steps = 20):\n",
    "    loc = False\n",
    "    threshold = 0.9\n",
    "    w, h = template.shape[::-1]\n",
    "    # for scale in np.append(np.linspace(0.2, 1.0, steps)[::-1], np.linspace(1.0, 2.0, steps)[1:]):\n",
    "    #     resized = imutils.resize(template, width = int(template.shape[1] * scale))\n",
    "    #     w, h = resized.shape[::-1]\n",
    "    #     res = cv2.matchTemplate(image_input,resized,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    #     loc = np.where( res >= threshold)\n",
    "    #     if len(list(zip(*loc[::-1]))) > 0:\n",
    "    #         # print(f'Matched on scale {scale}')\n",
    "    #         break\n",
    "    res = cv2.matchTemplate(image_input,template,cv2.TM_CCOEFF_NORMED)\n",
    "    loc = np.where( res >= threshold)\n",
    "\n",
    "    matches = []\n",
    "    mask = np.zeros(image_input.shape[:2], np.uint8)\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        if mask[pt[1] + int(round(h/2)), pt[0] + int(round(w/2))] != 255:\n",
    "            mask[pt[1]:pt[1]+h, pt[0]:pt[0]+w] = 255\n",
    "            matches.append((pt[0],pt[1],pt[0]+w,pt[1]+h))\n",
    "    return matches, (w,h), 1 #scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status = rich.status.Status(\"Scanning for Breach\")\n",
    "# status.start()\n",
    "# while True:\n",
    "#     screenshot = ImageGrab.grab()\n",
    "#     image_o = np.array(screenshot)[:, :, ::-1]\n",
    "#     image = cv2.cvtColor(image_o, cv2.COLOR_BGR2GRAY)\n",
    "#     solution_start = time.process_time()\n",
    "#     matches, match_size, scale = find_matches(image, header_template)\n",
    "#     elapsed_time = time.process_time() - solution_start\n",
    "#     status.update(f\"Scanning for Breach [{round(elapsed_time,2)}s]\")\n",
    "#     if len(matches):\n",
    "#         win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, -10000, -10000, 0, 0)\n",
    "#         time.sleep(1)\n",
    "#         status.stop()\n",
    "#         break\n",
    "# screenshot = ImageGrab.grab()\n",
    "# image_o = np.array(screenshot)[:, :, ::-1]\n",
    "# image = cv2.cvtColor(image_o, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches, match_size, scale = find_matches(image, header_template)\n",
    "header_pos = matches[0]\n",
    "header_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_highlight = image_o.copy()\n",
    "# _ = cv2.rectangle(matched_highlight, header_pos[:2], header_pos[2:], (0,0,255), 5)\n",
    "# cv2.imshow('Matched header', matched_highlight)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_bytes = {}\n",
    "playing_field_crop_o = image_o[header_pos[1]:, header_pos[0]:]\n",
    "playing_field_crop = cv2.cvtColor(playing_field_crop_o, cv2.COLOR_BGR2GRAY)\n",
    "for byte, template in byte_templates.items():\n",
    "    matches, match_size, scale = find_matches(playing_field_crop, template)\n",
    "    matched_bytes[byte] = matches\n",
    "matched_bytes_flat = [item for sublist in matched_bytes.values() for item in sublist]\n",
    "# matched_highlight = playing_field_crop_o.copy()\n",
    "# for match in matched_bytes_flat:\n",
    "#     cv2.rectangle(matched_highlight, match[:2], match[2:], (0,0,255), 2)\n",
    "# for byte, matches in matched_bytes.items():\n",
    "#     for match in matches:\n",
    "#         cv2.rectangle(matched_highlight, match[:2], match[2:], (0,0,255), -1)\n",
    "#         text_size, _ = cv2.getTextSize(byte, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "#         text_w, text_h = text_size\n",
    "#         cv2.putText(matched_highlight, byte, (match[0], match[1] + text_h + 1 - 1), cv2.FONT_HERSHEY_SIMPLEX, 1, (25,255,255), 3)\n",
    "# cv2.imshow('Matched bytes', matched_highlight)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_cf = 0.05\n",
    "min_x, max_x, min_y, max_y = min(matched_bytes_flat, key=lambda x: x[1])[1], max(matched_bytes_flat, key=lambda x: x[3])[3], min(matched_bytes_flat, key=lambda x: x[0])[0], max(matched_bytes_flat, key=lambda x: x[2])[2]\n",
    "min_x = int(round(min_x - (max_x-min_x)*space_cf))\n",
    "min_y = int(round(min_y - (max_y-min_y)*space_cf))\n",
    "max_x = int(round(max_x + (max_x-min_x)*space_cf))\n",
    "max_y = int(round(max_y + (max_y-min_y)*space_cf))\n",
    "cropped_field = playing_field_crop_o[min_x:max_x, min_y:max_y]\n",
    "# matched_highlight = cropped_field.copy()\n",
    "# for match in matched_bytes_flat:\n",
    "#     cv2.rectangle(matched_highlight, (match[0] - min_y, match[1] - min_x), (match[2] - min_y, match[3] - min_x), (0,0,255), 2)\n",
    "matched_highlight_field = cv2.cvtColor(cv2.cvtColor(cropped_field, cv2.COLOR_BGR2GRAY),cv2.COLOR_GRAY2RGB)\n",
    "for byte, matches in matched_bytes.items():\n",
    "    for match in matches:\n",
    "        byte_template = byte_templates[byte]\n",
    "        y1, y2 = match[0] - min_y, match[2] - min_y\n",
    "        x1, x2 = match[1] - min_x, match[3] - min_x\n",
    "        cv2.rectangle(matched_highlight_field, (y1-1, x1-1), (y2, x2), (0,255,0), 0)\n",
    "        highlighted_byte = cv2.merge((byte_template, byte_template, byte_template))\n",
    "        highlighted_byte[:,:,0] = 0\n",
    "        highlighted_byte[:,:,1] = 0\n",
    "        matched_highlight_field[x1:x2, y1:y2] = highlighted_byte\n",
    "        # text_size, _ = cv2.getTextSize(byte, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "        # text_w, text_h = text_size\n",
    "        # cv2.putText(matched_highlight, byte, (y1, x1 + text_h + 1 - 1), cv2.FONT_HERSHEY_SIMPLEX, 1, (25,255,255), 3)\n",
    "# cv2.imshow('Matched target', matched_highlight_field)\n",
    "# cv2.setWindowProperty('Matched target', cv2.WND_PROP_TOPMOST, 1)\n",
    "# cv2.waitKey(1000)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_template_o = cv2.imread('./templates/buffer_frame.png')\n",
    "buffer_template = cv2.cvtColor(buffer_template_o, cv2.COLOR_BGR2GRAY)\n",
    "buffer_matches, match_size, scale = find_matches(image, buffer_template)\n",
    "# matched_highlight = image_o.copy()\n",
    "# for match in buffer_matches:\n",
    "#     cv2.rectangle(matched_highlight, match[:2], match[2:], (0,0,255), 2)\n",
    "# cv2.imshow('Matched buffer', matched_highlight)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "buffer_size = len(buffer_matches)\n",
    "print(f'Buffer size - {buffer_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_min_x, buffer_max_x, buffer_min_y, buffer_max_y = min(buffer_matches, key=lambda x: x[1])[1], max(buffer_matches, key=lambda x: x[3])[3], min(buffer_matches, key=lambda x: x[0])[0], max(buffer_matches, key=lambda x: x[2])[2]\n",
    "buffer_min_x = int(round(buffer_min_x - (buffer_max_x-buffer_min_x)*0.7))\n",
    "buffer_min_y = int(round(buffer_min_y - (buffer_max_y-buffer_min_y)*0.08))\n",
    "buffer_max_x = int(round(buffer_max_x + (buffer_max_x-buffer_min_x)*0.4))\n",
    "buffer_max_y = int(round(buffer_max_y + (buffer_max_y-buffer_min_y)*0.08))\n",
    "cropped_buffer = image_o[buffer_min_x:buffer_max_x, buffer_min_y:buffer_max_y]\n",
    "matched_highlight_buffer = cv2.cvtColor(cv2.cvtColor(cropped_buffer, cv2.COLOR_BGR2GRAY),cv2.COLOR_GRAY2RGB)\n",
    "for match in buffer_matches:\n",
    "    y1, y2 = match[0] - buffer_min_y, match[2] - buffer_min_y\n",
    "    x1, x2 = match[1] - buffer_min_x, match[3] - buffer_min_x\n",
    "    cv2.rectangle(matched_highlight_buffer, (y1-5, x1-5), (y2+5, x2+5), (0,255,0), 0)\n",
    "    highlighted_buffer = cv2.merge((buffer_template, buffer_template, buffer_template))\n",
    "    highlighted_buffer[:,:,0] = 0\n",
    "    highlighted_buffer[:,:,1] = 0\n",
    "    matched_highlight_buffer[x1:x2, y1:y2] = highlighted_buffer\n",
    "# cv2.imshow('Matched buffer', matched_highlight_buffer)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_unique(input_list, deviation_percentage = 0.05):\n",
    "    input_list = input_list.copy()\n",
    "    input_list.sort()\n",
    "    average = input_list[0]\n",
    "    minimal, maximum = average, average\n",
    "    result = []\n",
    "    current_values = []\n",
    "    for input_item in input_list:\n",
    "        if input_item < average - average*deviation_percentage or input_item > average + average*deviation_percentage:\n",
    "            result.append({\n",
    "                \"average\": average,\n",
    "                \"minimal\": minimal,\n",
    "                \"maximum\": maximum,\n",
    "                \"values\": current_values\n",
    "            })\n",
    "            average = input_item\n",
    "            minimal, maximum = average, average\n",
    "            current_values = []\n",
    "        else:\n",
    "            current_values.append(input_item)\n",
    "            average = sum(current_values) / len(current_values)\n",
    "            minimal = min(minimal, input_item)\n",
    "            maximum = max(maximum, input_item)\n",
    "    result.append({\n",
    "        \"average\": average,\n",
    "        \"minimal\": minimal,\n",
    "        \"maximum\": maximum,\n",
    "        \"values\": current_values\n",
    "    })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_means = mean_unique([x[0] for x in matched_bytes_flat])\n",
    "y_means = mean_unique([x[1] for x in matched_bytes_flat])\n",
    "x_means, y_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_positions = {}\n",
    "rows = []\n",
    "for y,y_mean in enumerate(y_means):\n",
    "    row = []\n",
    "    cells_positions[y] = {}\n",
    "    for x, x_mean in enumerate(x_means):\n",
    "        for byte, matches in matched_bytes.items():\n",
    "            for match in matches:\n",
    "                if match[0] >= x_mean['minimal'] and match[0] <= x_mean[\"maximum\"] and match[1] >= y_mean['minimal'] and match[1] <= y_mean[\"maximum\"]:\n",
    "                    row.append(byte)    \n",
    "                    cells_positions[y][x] = match\n",
    "    print(row)\n",
    "    rows.append(row)\n",
    "rows, cells_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_target_bytes = {}\n",
    "cropped_non_field_o = playing_field_crop_o[:int(image.shape[0]-min_x-image.shape[0]*0.35), max_y:int(image.shape[1]-min_y-image.shape[1]*0.075)]\n",
    "cropped_non_field = cv2.cvtColor(cropped_non_field_o, cv2.COLOR_BGR2GRAY)\n",
    "for byte, template in target_byte_templates.items():\n",
    "    matches, match_size, scale = find_matches(cropped_non_field, template)\n",
    "    matched_target_bytes[byte] = matches\n",
    "matched_target_bytes_flat = [item for sublist in matched_target_bytes.values() for item in sublist]\n",
    "matched_highlight = cropped_non_field_o.copy()\n",
    "for match in matched_target_bytes_flat:\n",
    "    cv2.rectangle(matched_highlight, match[:2], match[2:], (0,0,255), 2)\n",
    "# cv2.imshow('Matched bytes', matched_highlight)\n",
    "# cv2.setWindowProperty('Matched bytes', cv2.WND_PROP_TOPMOST, 1)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_cf = 0.005\n",
    "targets_min_x, targets_max_x, targets_min_y, targets_max_y = min(matched_target_bytes_flat, key=lambda x: x[1])[1], max(matched_target_bytes_flat, key=lambda x: x[3])[3], min(matched_target_bytes_flat, key=lambda x: x[0])[0], cropped_non_field_o.shape[1]\n",
    "targets_min_x = int(round(targets_min_x - (targets_max_x-targets_min_x)*(space_cf*15)))\n",
    "targets_min_y = int(round(targets_min_y - (targets_max_y-targets_min_y)*space_cf))\n",
    "targets_max_x = int(round(targets_max_x + (targets_max_x-targets_min_x)/len(matched_target_bytes_flat)*(1.3)))\n",
    "targets_max_y = int(round(targets_max_y - (targets_max_y-targets_min_y)*(space_cf*2)))\n",
    "cropped_non_field = cropped_non_field_o[targets_min_x:targets_max_x, targets_min_y:targets_max_y]\n",
    "matched_highlight_targets = cropped_non_field.copy()\n",
    "for target_byte, target_matches in matched_target_bytes.items():\n",
    "    for target_match in target_matches:\n",
    "        byte_template = target_byte_templates[target_byte]\n",
    "        y1, y2 = target_match[0] - targets_min_y, target_match[2] - targets_min_y\n",
    "        x1, x2 = target_match[1] - targets_min_x, target_match[3] - targets_min_x\n",
    "        cv2.rectangle(matched_highlight_targets, (y1-1, x1-1), (y2, x2), (0,255,0), 0)\n",
    "        highlighted_byte = cv2.merge((byte_template, byte_template, byte_template))\n",
    "        highlighted_byte[:,:,0] = 0\n",
    "        highlighted_byte[:,:,1] = 0\n",
    "        matched_highlight_targets[x1:x2, y1:y2] = highlighted_byte\n",
    "# cv2.imshow('Matched targets', matched_highlight_targets)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x_means = mean_unique([x[0] for x in matched_target_bytes_flat])\n",
    "target_y_means = mean_unique([x[1] for x in matched_target_bytes_flat])\n",
    "target_x_means, target_y_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rows = []\n",
    "for target_n, y_mean in enumerate(target_y_means):\n",
    "    row = []\n",
    "    for x_mean in target_x_means:\n",
    "        for byte, matches in matched_target_bytes.items():\n",
    "            for match in matches:\n",
    "                if match[0] >= x_mean['minimal'] and match[0] <= x_mean[\"maximum\"] and match[1] >= y_mean['minimal'] and match[1] <= y_mean[\"maximum\"]:\n",
    "                    row.append(byte)\n",
    "    print(f\"Target {target_n+1} - {row}\")\n",
    "    target_rows.append(row)\n",
    "target_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_image = np.zeros((matched_highlight_field.shape[0] + matched_highlight_targets.shape[0],matched_highlight_targets.shape[1],3), np.uint8)\n",
    "summary_image[0:matched_highlight_targets.shape[0], 0:matched_highlight_targets.shape[1]] = matched_highlight_targets\n",
    "summary_image[matched_highlight_targets.shape[0]:summary_image.shape[0], 0:matched_highlight_field.shape[1]] = matched_highlight_field\n",
    "# matched_highlight_buffer\n",
    "summary_image[matched_highlight_targets.shape[0]:matched_highlight_targets.shape[0]+matched_highlight_buffer.shape[0],matched_highlight_field.shape[1]:matched_highlight_field.shape[1]+matched_highlight_buffer.shape[1]] = matched_highlight_buffer\n",
    "text_start_y, text_start_x = matched_highlight_targets.shape[0] + matched_highlight_buffer.shape[0] + 30, matched_highlight_field.shape[1] + 5\n",
    "cv2.putText(summary_image, f\"Buffer size - {buffer_size}\", (text_start_x, text_start_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "text_start_y += 20\n",
    "cv2.putText(summary_image, f\"Matrix:\", (text_start_x, text_start_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "text_start_y += 40\n",
    "for row in rows:\n",
    "    for col in row:\n",
    "        cv2.putText(summary_image, col, (text_start_x, text_start_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 1)\n",
    "        text_start_x += 50\n",
    "    text_start_x = matched_highlight_field.shape[1] + 5\n",
    "    text_start_y += 25\n",
    "text_start_y += 20\n",
    "cv2.putText(summary_image, f\"Targets:\", (text_start_x, text_start_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 1)\n",
    "text_start_y += 40\n",
    "for target in target_rows:\n",
    "    cv2.putText(summary_image, ':'.join(target), (text_start_x, text_start_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 1)\n",
    "    text_start_y += 25\n",
    "cv2.imshow('Summary', summary_image)\n",
    "cv2.setWindowProperty('Summary', cv2.WND_PROP_TOPMOST, 1)\n",
    "cv2.waitKey(1500)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Direction(Enum):\n",
    "    ROW = 1\n",
    "    COL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_solution(buffer, targets):\n",
    "    buffer_str = ''.join(buffer)\n",
    "    targets = [''.join(target) for target in targets]\n",
    "    score = 0\n",
    "    for n_target, target in enumerate(targets):\n",
    "        if target in buffer_str:\n",
    "            score += len(targets)-n_target+1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Brute force solver\n",
    "\n",
    "def walk_puzzle(rows, targets, buffer_left = 8, position = (Direction.COL, 0), buffer = [], path=[], used=[]):\n",
    "    # print(f\"Walking {position}, {buffer_left} buffer left\")\n",
    "    n_rows = len(rows)\n",
    "    n_cols = len(rows[0])\n",
    "    paths = {}\n",
    "    if position[0] == Direction.COL:\n",
    "        for n in range(n_cols):\n",
    "            coords = (position[1], n)\n",
    "            if coords in used:\n",
    "                continue\n",
    "            byte = rows[position[1]][n]\n",
    "            new_buffer = [*buffer, byte]\n",
    "            new_path = [*path, (Direction.ROW, n)]\n",
    "            if buffer_left == 1:\n",
    "                paths[tuple(new_path)] = (rank_solution(new_buffer, targets), new_buffer)\n",
    "            else:\n",
    "                paths = {**paths,**walk_puzzle(rows, targets, buffer_left-1, (Direction.ROW, n), new_buffer, new_path, [*used, coords])}\n",
    "    else:\n",
    "        for n in range(n_rows):\n",
    "            coords = (n, position[1])\n",
    "            if coords in used:\n",
    "                continue\n",
    "            byte = rows[n][position[1]]\n",
    "            new_buffer = [*buffer, byte]\n",
    "            new_path = [*path, (Direction.COL, n)]\n",
    "            if buffer_left == 1:\n",
    "                paths[tuple(new_path)] = (rank_solution(new_buffer, targets), new_buffer)\n",
    "            else:\n",
    "                paths = {**paths, **walk_puzzle(rows, targets, buffer_left-1, (Direction.COL, n), new_buffer, new_path, [*used, coords])}\n",
    "    return paths\n",
    "\n",
    "# solving_status = rich.status.Status(\"Solving\")\n",
    "# solving_status.start()\n",
    "# solution_start = time.process_time()\n",
    "# solutions = walk_puzzle(rows, target_rows, min(buffer_size,8))\n",
    "# solving_status.stop()\n",
    "# print(f\"Solved in {time.process_time() - solution_start}s\")\n",
    "# solution = max(solutions, key=solutions.get)\n",
    "# solution, solutions[solution][0], solutions[solution][1]\n",
    "# solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ranked walker\n",
    "\n",
    "def walk_puzzle(rows, targets, buffer_left = 8, position = (Direction.COL, 0), buffer = [], path=[], used=[], max_score = 3):\n",
    "    # print(f\"Walking {position}, {buffer_left} buffer left\")\n",
    "    n_rows = len(rows)\n",
    "    n_cols = len(rows[0])\n",
    "    paths = {}\n",
    "    if position[0] == Direction.COL:\n",
    "        for n in range(n_cols):\n",
    "            coords = (position[1], n)\n",
    "            if coords in used:\n",
    "                continue\n",
    "            byte = rows[position[1]][n]\n",
    "            new_buffer = [*buffer, byte]\n",
    "            new_path = [*path, (Direction.ROW, n)]\n",
    "            score = rank_solution(new_buffer, targets)\n",
    "            paths[tuple(new_path)] = (score, new_buffer)\n",
    "            if score >= max_score:\n",
    "                return paths, tuple(new_path)\n",
    "            if buffer_left != 1:\n",
    "                walked, solution = walk_puzzle(rows, targets, buffer_left-1, (Direction.ROW, n), new_buffer, new_path, [*used, coords], max_score)\n",
    "                paths = {**paths,**walked}\n",
    "                if solution != None:\n",
    "                    return paths, solution\n",
    "    else:\n",
    "        for n in range(n_rows):\n",
    "            coords = (n, position[1])\n",
    "            if coords in used:\n",
    "                continue\n",
    "            byte = rows[n][position[1]]\n",
    "            new_buffer = [*buffer, byte]\n",
    "            new_path = [*path, (Direction.COL, n)]\n",
    "            score = rank_solution(new_buffer, targets)\n",
    "            paths[tuple(new_path)] = (score, new_buffer)\n",
    "            if score >= max_score:\n",
    "                return paths, tuple(new_path)\n",
    "            if buffer_left != 1:\n",
    "                walked, solution = walk_puzzle(rows, targets, buffer_left-1, (Direction.COL, n), new_buffer, new_path, [*used, coords], max_score)\n",
    "                paths = {**paths, **walked}\n",
    "                if solution != None:\n",
    "                    return paths, solution\n",
    "    return paths, None\n",
    "\n",
    "solving_status = rich.status.Status(\"Solving\")\n",
    "solving_status.start()\n",
    "solution_start = time.process_time()\n",
    "solutions, solution = walk_puzzle(rows, target_rows, buffer_size, max_score=sum([len(target_rows)-n+1 for n,r in enumerate(target_rows)]))\n",
    "solving_status.stop()\n",
    "print(f\"Solved in {time.process_time() - solution_start}s\")\n",
    "if solution == None:\n",
    "    solution = max(solutions, key=solutions.get)\n",
    "solution, solutions[solution][0], solutions[solution][1]\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_highlight = cropped_field.copy()\n",
    "solution_highlight_img = image_o.copy()\n",
    "current_row, current_col = 0, 0\n",
    "positions = []\n",
    "for step_n, step in enumerate(solution):\n",
    "    if step[0] == Direction.ROW:\n",
    "        cell_position = (current_col,step[1])\n",
    "        position = cells_positions[current_col][step[1]]\n",
    "        current_row = step[1]\n",
    "    else:\n",
    "        cell_position = (step[1], current_row)\n",
    "        position = cells_positions[step[1]][current_row]\n",
    "        current_col = step[1]\n",
    "    cv2.rectangle(solution_highlight, (position[0] - min_y, position[1] - min_x), (position[2] - min_y, position[3] - min_x), (0,0,255), 2)\n",
    "    cv2.putText(solution_highlight, f'{step_n+1}', (position[0]- min_y, position[1] - min_x), cv2.FONT_HERSHEY_SIMPLEX, 1, (25,255,255), 3)\n",
    "    center_coord = (int((position[0]+position[2])/2+header_pos[0]), int((position[1]+position[3])/2+header_pos[1]))\n",
    "    positions.append((center_coord, cell_position))\n",
    "    cv2.circle(solution_highlight_img, center_coord, 20, (0,0,255), 2)\n",
    "    text_size, _ = cv2.getTextSize(f'{step_n+1}', cv2.FONT_HERSHEY_SIMPLEX, 1, 3)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.putText(solution_highlight_img, f'{step_n+1}', (center_coord[0]-int(text_w/2), center_coord[1]-int(text_h)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,100,255), 3)\n",
    "cv2.imshow('Solution', solution_highlight)\n",
    "# cv2.imshow('Solution', solution_highlight_img)\n",
    "cv2.setWindowProperty('Solution', cv2.WND_PROP_TOPMOST, 1)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "time.sleep(0.5)\n",
    "for n_pos, (pos,cell_pos) in enumerate(positions):\n",
    "    print(f\"{n_pos} - {rows[cell_pos[0]][cell_pos[1]]} - {cell_pos} {pos}\")\n",
    "    # win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, -10000, -10000, 0, 0)\n",
    "    # time.sleep(0.01)\n",
    "    # win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, pos[0], pos[1], 0, 0)\n",
    "    # time.sleep(0.01)\n",
    "    # win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0)\n",
    "    # time.sleep(0.01)\n",
    "    # win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,0,0)\n",
    "    # time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script solver.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "580d4d30777d3bded641df0876a9b9088d57b39e3bf11175484e55c42a2d01b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
